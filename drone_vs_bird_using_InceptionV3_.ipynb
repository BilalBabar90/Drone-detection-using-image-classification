{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUF55Z6hNV90",
        "outputId": "4d4fc2ba-3ff2-42b0-9ad6-8804be355b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDu4yzETPC2O",
        "outputId": "ae494a49-7416-47e2-ad33-5869cf476f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 660 validated image filenames belonging to 2 classes.\n",
            "Found 83 validated image filenames belonging to 2 classes.\n",
            "Found 83 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 2 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 5.9298 - accuracy: 0.6134\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95000, saving model to /content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/41 [==============================] - 25s 497ms/step - loss: 5.9298 - accuracy: 0.6134 - val_loss: 0.3313 - val_accuracy: 0.9500 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 0.7717\n",
            "Epoch 2: val_accuracy did not improve from 0.95000\n",
            "41/41 [==============================] - 15s 356ms/step - loss: 1.6447 - accuracy: 0.7717 - val_loss: 0.1851 - val_accuracy: 0.9500 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.8447\n",
            "Epoch 3: val_accuracy did not improve from 0.95000\n",
            "41/41 [==============================] - 15s 369ms/step - loss: 0.7347 - accuracy: 0.8447 - val_loss: 0.2853 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8773\n",
            "Epoch 4: val_accuracy did not improve from 0.95000\n",
            "41/41 [==============================] - 15s 352ms/step - loss: 0.4430 - accuracy: 0.8773 - val_loss: 0.1484 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8556\n",
            "Epoch 5: val_accuracy did not improve from 0.95000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 0.5509 - accuracy: 0.8556 - val_loss: 0.2949 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8696\n",
            "Epoch 6: val_accuracy did not improve from 0.95000\n",
            "41/41 [==============================] - 14s 340ms/step - loss: 0.4705 - accuracy: 0.8696 - val_loss: 0.1908 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8820\n",
            "Epoch 7: val_accuracy improved from 0.95000 to 0.96250, saving model to /content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5\n",
            "41/41 [==============================] - 19s 450ms/step - loss: 0.2912 - accuracy: 0.8820 - val_loss: 0.3238 - val_accuracy: 0.9625 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9224\n",
            "Epoch 8: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 16s 374ms/step - loss: 0.2181 - accuracy: 0.9224 - val_loss: 0.2120 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.8929\n",
            "Epoch 9: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 347ms/step - loss: 0.2747 - accuracy: 0.8929 - val_loss: 0.1869 - val_accuracy: 0.9625 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9037\n",
            "Epoch 10: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 354ms/step - loss: 0.2206 - accuracy: 0.9037 - val_loss: 0.1387 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 11/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.9161\n",
            "Epoch 11: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 0.1921 - accuracy: 0.9161 - val_loss: 0.1501 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 12/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9286\n",
            "Epoch 12: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 348ms/step - loss: 0.1941 - accuracy: 0.9286 - val_loss: 0.1369 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 13/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9345\n",
            "Epoch 13: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 353ms/step - loss: 0.1504 - accuracy: 0.9345 - val_loss: 0.1352 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 14/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9379\n",
            "Epoch 14: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 345ms/step - loss: 0.1527 - accuracy: 0.9379 - val_loss: 0.1394 - val_accuracy: 0.9500 - lr: 2.0000e-04\n",
            "Epoch 15/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9503\n",
            "Epoch 15: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 341ms/step - loss: 0.1349 - accuracy: 0.9503 - val_loss: 0.1626 - val_accuracy: 0.9250 - lr: 2.0000e-04\n",
            "Epoch 16/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9441\n",
            "Epoch 16: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 15s 374ms/step - loss: 0.1687 - accuracy: 0.9441 - val_loss: 0.1156 - val_accuracy: 0.9500 - lr: 2.0000e-04\n",
            "Epoch 17/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9317\n",
            "Epoch 17: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 342ms/step - loss: 0.2147 - accuracy: 0.9317 - val_loss: 0.1203 - val_accuracy: 0.9625 - lr: 2.0000e-04\n",
            "Epoch 18/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9457\n",
            "Epoch 18: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 344ms/step - loss: 0.1359 - accuracy: 0.9457 - val_loss: 0.1192 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 19/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9410\n",
            "Epoch 19: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 352ms/step - loss: 0.1438 - accuracy: 0.9410 - val_loss: 0.1269 - val_accuracy: 0.9250 - lr: 2.0000e-04\n",
            "Epoch 20/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9410\n",
            "Epoch 20: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 350ms/step - loss: 0.1640 - accuracy: 0.9410 - val_loss: 0.1130 - val_accuracy: 0.9500 - lr: 2.0000e-04\n",
            "Epoch 21/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9421\n",
            "Epoch 21: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 349ms/step - loss: 0.1519 - accuracy: 0.9421 - val_loss: 0.1361 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 22/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9457\n",
            "Epoch 22: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 346ms/step - loss: 0.1120 - accuracy: 0.9457 - val_loss: 0.1496 - val_accuracy: 0.9250 - lr: 2.0000e-04\n",
            "Epoch 23/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9472\n",
            "Epoch 23: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 15s 353ms/step - loss: 0.1489 - accuracy: 0.9472 - val_loss: 0.1262 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 24/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9472\n",
            "Epoch 24: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 0.1362 - accuracy: 0.9472 - val_loss: 0.1316 - val_accuracy: 0.9500 - lr: 2.0000e-04\n",
            "Epoch 25/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9457\n",
            "Epoch 25: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 342ms/step - loss: 0.1453 - accuracy: 0.9457 - val_loss: 0.1616 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 26/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9519\n",
            "Epoch 26: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 13s 317ms/step - loss: 0.1287 - accuracy: 0.9519 - val_loss: 0.1475 - val_accuracy: 0.9375 - lr: 4.0000e-05\n",
            "Epoch 27/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9565\n",
            "Epoch 27: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 338ms/step - loss: 0.1181 - accuracy: 0.9565 - val_loss: 0.1457 - val_accuracy: 0.9500 - lr: 4.0000e-05\n",
            "Epoch 28/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9612\n",
            "Epoch 28: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 342ms/step - loss: 0.0878 - accuracy: 0.9612 - val_loss: 0.1392 - val_accuracy: 0.9375 - lr: 4.0000e-05\n",
            "Epoch 29/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9643\n",
            "Epoch 29: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 346ms/step - loss: 0.0982 - accuracy: 0.9643 - val_loss: 0.1362 - val_accuracy: 0.9375 - lr: 4.0000e-05\n",
            "Epoch 30/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9643\n",
            "Epoch 30: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 354ms/step - loss: 0.1009 - accuracy: 0.9643 - val_loss: 0.1263 - val_accuracy: 0.9625 - lr: 4.0000e-05\n",
            "Epoch 31/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9612\n",
            "Epoch 31: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 349ms/step - loss: 0.0981 - accuracy: 0.9612 - val_loss: 0.1182 - val_accuracy: 0.9625 - lr: 1.0000e-05\n",
            "Epoch 32/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9643\n",
            "Epoch 32: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 346ms/step - loss: 0.1203 - accuracy: 0.9643 - val_loss: 0.1373 - val_accuracy: 0.9500 - lr: 1.0000e-05\n",
            "Epoch 33/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9519\n",
            "Epoch 33: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 14s 344ms/step - loss: 0.1169 - accuracy: 0.9519 - val_loss: 0.1286 - val_accuracy: 0.9500 - lr: 1.0000e-05\n",
            "Epoch 34/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9472\n",
            "Epoch 34: val_accuracy did not improve from 0.96250\n",
            "41/41 [==============================] - 15s 363ms/step - loss: 0.1132 - accuracy: 0.9472 - val_loss: 0.1367 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 35/60\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9565\n",
            "Epoch 35: val_accuracy did not improve from 0.96250\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "41/41 [==============================] - 14s 341ms/step - loss: 0.0857 - accuracy: 0.9565 - val_loss: 0.1414 - val_accuracy: 0.9500 - lr: 1.0000e-05\n",
            "Epoch 35: early stopping\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.1094 - accuracy: 0.9518\n",
            "Test Accuracy: 0.9518072009086609\n",
            "Test loss: 0.1093948557972908\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import InceptionV3\n",
        "from keras import layers, models\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define paths\n",
        "base_path = '/content/drive/MyDrive/dataset_xml_format/dataset_xml_format/BirdVsDrone'\n",
        "birds_path = os.path.join(base_path, 'Birds')\n",
        "drones_path = os.path.join(base_path, 'Drones')\n",
        "\n",
        "# List all files in the folders\n",
        "birds_files = [os.path.join(birds_path, file) for file in os.listdir(birds_path)]\n",
        "drones_files = [os.path.join(drones_path, file) for file in os.listdir(drones_path)]\n",
        "\n",
        "# Create labels\n",
        "birds_labels = [0] * len(birds_files)\n",
        "drones_labels = [1] * len(drones_files)\n",
        "\n",
        "# Combine data and labels\n",
        "all_data_paths = birds_files + drones_files\n",
        "all_labels = birds_labels + drones_labels\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    all_data_paths, all_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Further split the validation set\n",
        "validation_paths, test_paths, validation_labels, test_labels = train_test_split(\n",
        "    test_paths, test_labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert labels to strings\n",
        "train_labels = [str(label) for label in train_labels]\n",
        "validation_labels = [str(label) for label in validation_labels]\n",
        "test_labels = [str(label) for label in test_labels]\n",
        "\n",
        "# Create dataframes for train, validation, and test sets\n",
        "train_df = pd.DataFrame({'path': train_paths, 'label': train_labels})\n",
        "validation_df = pd.DataFrame({'path': validation_paths, 'label': validation_labels})\n",
        "test_df = pd.DataFrame({'path': test_paths, 'label': test_labels})\n",
        "\n",
        "# Use ImageDataGenerator for data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create data generators from dataframes\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_dataframe(\n",
        "    validation_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "# Unfreeze the last 10 layers in the base model\n",
        "\n",
        "\n",
        "# Define the base model (InceptionV3)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "# Unfreeze the last 10 layers in the base model\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a custom model for classification\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks\n",
        "checkpoint_path = '/content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5'\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='val_accuracy',  # You can change this metric based on your preference\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=60,\n",
        "    callbacks=[checkpoint,early_stopping, reduce_lr,]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Test loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6-Zr91H-RgB3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b11c09a-30f2-4f65-8042-53106f749b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of birds in test set: 77\n",
            "Number of drones in test set: 73\n",
            "Found 1996 validated image filenames belonging to 2 classes.\n",
            "Found 350 validated image filenames belonging to 2 classes.\n",
            "Found 150 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 3 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            " 33/124 [======>.......................] - ETA: 22s - loss: 0.0817 - accuracy: 0.9640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124/124 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9652\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97619, saving model to /content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 50s 346ms/step - loss: 0.0845 - accuracy: 0.9652 - val_loss: 0.0669 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 2/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9677\n",
            "Epoch 2: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 40s 324ms/step - loss: 0.0839 - accuracy: 0.9677 - val_loss: 0.0682 - val_accuracy: 0.9732 - lr: 1.0000e-05\n",
            "Epoch 3/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9631\n",
            "Epoch 3: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 42s 338ms/step - loss: 0.0900 - accuracy: 0.9631 - val_loss: 0.0691 - val_accuracy: 0.9732 - lr: 1.0000e-05\n",
            "Epoch 4/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9591\n",
            "Epoch 4: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 43s 350ms/step - loss: 0.0983 - accuracy: 0.9591 - val_loss: 0.0681 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 5/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9702\n",
            "Epoch 5: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 38s 308ms/step - loss: 0.0751 - accuracy: 0.9702 - val_loss: 0.0676 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 6/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9672\n",
            "Epoch 6: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 39s 315ms/step - loss: 0.0847 - accuracy: 0.9672 - val_loss: 0.0676 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 7/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9682\n",
            "Epoch 7: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 42s 336ms/step - loss: 0.0781 - accuracy: 0.9682 - val_loss: 0.0674 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 8/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9636\n",
            "Epoch 8: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 38s 308ms/step - loss: 0.0850 - accuracy: 0.9636 - val_loss: 0.0678 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 9/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9677\n",
            "Epoch 9: val_accuracy did not improve from 0.97619\n",
            "124/124 [==============================] - 40s 325ms/step - loss: 0.0808 - accuracy: 0.9677 - val_loss: 0.0669 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 10/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9667\n",
            "Epoch 10: val_accuracy improved from 0.97619 to 0.97917, saving model to /content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5\n",
            "124/124 [==============================] - 46s 371ms/step - loss: 0.0855 - accuracy: 0.9667 - val_loss: 0.0665 - val_accuracy: 0.9792 - lr: 1.0000e-05\n",
            "Epoch 11/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9672\n",
            "Epoch 11: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 39s 314ms/step - loss: 0.0741 - accuracy: 0.9672 - val_loss: 0.0675 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 12/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9591\n",
            "Epoch 12: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 40s 322ms/step - loss: 0.0926 - accuracy: 0.9591 - val_loss: 0.0687 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 13/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9727\n",
            "Epoch 13: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 307ms/step - loss: 0.0805 - accuracy: 0.9727 - val_loss: 0.0675 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 14/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9672\n",
            "Epoch 14: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 304ms/step - loss: 0.0844 - accuracy: 0.9672 - val_loss: 0.0661 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 15/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9677\n",
            "Epoch 15: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 301ms/step - loss: 0.0763 - accuracy: 0.9677 - val_loss: 0.0659 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 16/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9667\n",
            "Epoch 16: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 39s 313ms/step - loss: 0.0859 - accuracy: 0.9667 - val_loss: 0.0674 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 17/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9687\n",
            "Epoch 17: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 41s 332ms/step - loss: 0.0750 - accuracy: 0.9687 - val_loss: 0.0671 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 18/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9692\n",
            "Epoch 18: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 309ms/step - loss: 0.0789 - accuracy: 0.9692 - val_loss: 0.0674 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 19/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9732\n",
            "Epoch 19: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 303ms/step - loss: 0.0673 - accuracy: 0.9732 - val_loss: 0.0677 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 20/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9682\n",
            "Epoch 20: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 39s 317ms/step - loss: 0.0777 - accuracy: 0.9682 - val_loss: 0.0670 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 21/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9596\n",
            "Epoch 21: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 42s 338ms/step - loss: 0.0975 - accuracy: 0.9596 - val_loss: 0.0697 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 22/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9692\n",
            "Epoch 22: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 40s 326ms/step - loss: 0.0778 - accuracy: 0.9692 - val_loss: 0.0705 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 23/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9677\n",
            "Epoch 23: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 41s 330ms/step - loss: 0.0798 - accuracy: 0.9677 - val_loss: 0.0699 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 24/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9646\n",
            "Epoch 24: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 41s 332ms/step - loss: 0.0829 - accuracy: 0.9646 - val_loss: 0.0693 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 25/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9687\n",
            "Epoch 25: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 41s 331ms/step - loss: 0.0746 - accuracy: 0.9687 - val_loss: 0.0682 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 26/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9652\n",
            "Epoch 26: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 39s 311ms/step - loss: 0.0836 - accuracy: 0.9652 - val_loss: 0.0677 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 27/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9712\n",
            "Epoch 27: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 38s 306ms/step - loss: 0.0761 - accuracy: 0.9712 - val_loss: 0.0683 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 28/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9712\n",
            "Epoch 28: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 40s 320ms/step - loss: 0.0659 - accuracy: 0.9712 - val_loss: 0.0677 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 29/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9672\n",
            "Epoch 29: val_accuracy did not improve from 0.97917\n",
            "124/124 [==============================] - 43s 351ms/step - loss: 0.0778 - accuracy: 0.9672 - val_loss: 0.0669 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 30/60\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9672\n",
            "Epoch 30: val_accuracy did not improve from 0.97917\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "124/124 [==============================] - 40s 322ms/step - loss: 0.0782 - accuracy: 0.9672 - val_loss: 0.0665 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
            "Epoch 30: early stopping\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.0424 - accuracy: 0.9867\n",
            "Test Accuracy: 0.9866666793823242\n",
            "Test loss: 0.04237006604671478\n",
            "10/10 [==============================] - 2s 85ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99        77\n",
            "           1       0.99      0.99      0.99        73\n",
            "\n",
            "    accuracy                           0.99       150\n",
            "   macro avg       0.99      0.99      0.99       150\n",
            "weighted avg       0.99      0.99      0.99       150\n",
            "\n",
            "Confusion Matrix:\n",
            "[[76  1]\n",
            " [ 1 72]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the weights from the model_checkpoint.h5 file\n",
        "model = load_model('/content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5')\n",
        "\n",
        "# Count birds and drones in the test set\n",
        "bird_count = test_df[test_df['label'] == '0'].shape[0]\n",
        "drone_count = test_df[test_df['label'] == '1'].shape[0]\n",
        "\n",
        "print(f\"Number of birds in test set: {bird_count}\")\n",
        "print(f\"Number of drones in test set: {drone_count}\")\n",
        "\n",
        "# Use ImageDataGenerator for data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create data generators from dataframes (assuming you have already defined train_df, validation_df, and test_df)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_dataframe(\n",
        "    validation_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "# Set up callbacks\n",
        "checkpoint_path = '/content/drive/MyDrive/dataset_xml_format/dataset_xml_format/model_checkpoint.h5'\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=60,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Test loss: {test_loss}')\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_predictions = model.predict(test_generator)\n",
        "test_predictions_binary = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "# Convert labels to binary format\n",
        "test_labels_binary = test_df['label'].astype(int)\n",
        "\n",
        "# Convert true labels to binary\n",
        "test_true_labels = (np.array(test_generator.classes) > 0.4).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(test_true_labels, test_predictions_binary)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(test_true_labels, test_predictions_binary)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Birds', 'Drones'], yticklabels=['Birds', 'Drones'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3pKjimVm69kE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}